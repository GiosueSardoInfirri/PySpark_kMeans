{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k means ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/27 14:20:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# import the python libraries to create/connect to a Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# build a SparkSession \n",
    "#   connect to the master node on the port where the master node is listening (7077)\n",
    "#   declare the app name \n",
    "#   configure the executor memory to 512 MB\n",
    "#   either *connect* or *create* a new Spark Context\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\")\\\n",
    "    .appName(\"prova iniziale\")\\\n",
    "    .config(\"spark.executor.memory\", \"512m\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ccd882baceb6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>prova iniziale</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1d90564c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ccd882baceb6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>prova iniziale</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://spark-master:7077 appName=prova iniziale>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a spark context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# print its status\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn # to be run at the launch of \"docker compose up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.datasets #va installato\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.functions import stddev\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe directly from sklearn\n",
    "prova =  sklearn.datasets.fetch_kddcup99(percent10 = True, as_frame = True)\n",
    "X = prova.data\n",
    "\n",
    "# prova = sc.parallelize(sklearn.datasets.fetch_kddcup99(percent10 = True, as_frame = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494016</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>310</td>\n",
       "      <td>1881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494017</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>282</td>\n",
       "      <td>2286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494018</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>203</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494019</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>291</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494020</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494021 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration protocol_type  service   flag src_bytes dst_bytes land  \\\n",
       "0             0        b'tcp'  b'http'  b'SF'       181      5450    0   \n",
       "1             0        b'tcp'  b'http'  b'SF'       239       486    0   \n",
       "2             0        b'tcp'  b'http'  b'SF'       235      1337    0   \n",
       "3             0        b'tcp'  b'http'  b'SF'       219      1337    0   \n",
       "4             0        b'tcp'  b'http'  b'SF'       217      2032    0   \n",
       "...         ...           ...      ...    ...       ...       ...  ...   \n",
       "494016        0        b'tcp'  b'http'  b'SF'       310      1881    0   \n",
       "494017        0        b'tcp'  b'http'  b'SF'       282      2286    0   \n",
       "494018        0        b'tcp'  b'http'  b'SF'       203      1200    0   \n",
       "494019        0        b'tcp'  b'http'  b'SF'       291      1200    0   \n",
       "494020        0        b'tcp'  b'http'  b'SF'       219      1234    0   \n",
       "\n",
       "       wrong_fragment urgent hot  ... dst_host_count dst_host_srv_count  \\\n",
       "0                   0      0   0  ...              9                  9   \n",
       "1                   0      0   0  ...             19                 19   \n",
       "2                   0      0   0  ...             29                 29   \n",
       "3                   0      0   0  ...             39                 39   \n",
       "4                   0      0   0  ...             49                 49   \n",
       "...               ...    ...  ..  ...            ...                ...   \n",
       "494016              0      0   0  ...             86                255   \n",
       "494017              0      0   0  ...              6                255   \n",
       "494018              0      0   0  ...             16                255   \n",
       "494019              0      0   0  ...             26                255   \n",
       "494020              0      0   0  ...              6                255   \n",
       "\n",
       "       dst_host_same_srv_rate dst_host_diff_srv_rate  \\\n",
       "0                         1.0                    0.0   \n",
       "1                         1.0                    0.0   \n",
       "2                         1.0                    0.0   \n",
       "3                         1.0                    0.0   \n",
       "4                         1.0                    0.0   \n",
       "...                       ...                    ...   \n",
       "494016                    1.0                    0.0   \n",
       "494017                    1.0                    0.0   \n",
       "494018                    1.0                    0.0   \n",
       "494019                    1.0                    0.0   \n",
       "494020                    1.0                    0.0   \n",
       "\n",
       "       dst_host_same_src_port_rate dst_host_srv_diff_host_rate  \\\n",
       "0                             0.11                         0.0   \n",
       "1                             0.05                         0.0   \n",
       "2                             0.03                         0.0   \n",
       "3                             0.03                         0.0   \n",
       "4                             0.02                         0.0   \n",
       "...                            ...                         ...   \n",
       "494016                        0.01                        0.05   \n",
       "494017                        0.17                        0.05   \n",
       "494018                        0.06                        0.05   \n",
       "494019                        0.04                        0.05   \n",
       "494020                        0.17                        0.05   \n",
       "\n",
       "       dst_host_serror_rate dst_host_srv_serror_rate dst_host_rerror_rate  \\\n",
       "0                       0.0                      0.0                  0.0   \n",
       "1                       0.0                      0.0                  0.0   \n",
       "2                       0.0                      0.0                  0.0   \n",
       "3                       0.0                      0.0                  0.0   \n",
       "4                       0.0                      0.0                  0.0   \n",
       "...                     ...                      ...                  ...   \n",
       "494016                  0.0                     0.01                  0.0   \n",
       "494017                  0.0                     0.01                  0.0   \n",
       "494018                 0.06                     0.01                  0.0   \n",
       "494019                 0.04                     0.01                  0.0   \n",
       "494020                  0.0                     0.01                  0.0   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "494016                      0.0  \n",
       "494017                      0.0  \n",
       "494018                      0.0  \n",
       "494019                      0.0  \n",
       "494020                      0.0  \n",
       "\n",
       "[494021 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataframe (to be deleted for a bigger dataframe) (TO BE DELETED)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Spark dataframe\n",
    "And then acquire important informations about the dataframe: # columns, # rows, # partitions, the schema, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/spark-3.3.2-bin-hadoop3/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/bin/spark-3.3.2-bin-hadoop3/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# Create the spark dataframe with a smaller chunk of data (just to work easily)\n",
    "X_smaller = X.iloc[random.sample(range(1, len(X.index)), 5_000)]\n",
    "spark_X = spark.createDataFrame(X_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/27 14:20:59 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[duration: bigint, protocol_type: binary, service: binary, flag: binary, src_bytes: bigint, dst_bytes: bigint, land: bigint, wrong_fragment: bigint, urgent: bigint, hot: bigint, num_failed_logins: bigint, logged_in: bigint, num_compromised: bigint, root_shell: bigint, su_attempted: bigint, num_root: bigint, num_file_creations: bigint, num_shells: bigint, num_access_files: bigint, num_outbound_cmds: bigint, is_host_login: bigint, is_guest_login: bigint, count: bigint, srv_count: bigint, serror_rate: double, srv_serror_rate: double, rerror_rate: double, srv_rerror_rate: double, same_srv_rate: double, diff_srv_rate: double, srv_diff_host_rate: double, dst_host_count: bigint, dst_host_srv_count: bigint, dst_host_same_srv_rate: double, dst_host_diff_srv_rate: double, dst_host_same_src_port_rate: double, dst_host_srv_diff_host_rate: double, dst_host_serror_rate: double, dst_host_srv_serror_rate: double, dst_host_rerror_rate: double, dst_host_srv_rerror_rate: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lock the spark dataframe\n",
    "spark_X.persist() # non serve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of partitions the DataFrame is divided into the three workers yet\n",
    "spark_X.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the number of rows and columns in the dataframe\n",
    "n_rows = spark_X.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO CHANGE THE COLUMN/ROWS NUMBER EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the non-numerical values in an easy way\n",
    "# clean_X = spark_X.select('*').drop('protocol_type', 'service', 'flag')\n",
    "# clean_X.printSchema()\n",
    "\n",
    "# Delete the non-numerical values in a reusable way\n",
    "col_type = np.array(spark_X.dtypes)\n",
    "types = col_type[:,1] \n",
    "colnames = col_type[:,0]\n",
    "clean_X = spark_X.select([col(colnames[i]) for i in range(len(colnames)) if not types[i] == 'binary'])\n",
    "# clean_X.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.6077400e+01, 1.9860712e+03, 5.9295700e+02, 0.0000000e+00,\n",
       "        7.8000000e-03, 0.0000000e+00, 4.3400000e-02, 0.0000000e+00,\n",
       "        1.5160000e-01, 6.6000000e-03, 2.0000000e-04, 0.0000000e+00,\n",
       "        1.4000000e-02, 4.0000000e-03, 8.0000000e-04, 8.0000000e-04,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.2000000e-03, 3.3276860e+02,\n",
       "        2.9312240e+02, 1.7512000e-01, 1.7471200e-01, 5.7036000e-02,\n",
       "        5.7702000e-02, 7.9374000e-01, 2.0272000e-02, 2.9096000e-02,\n",
       "        2.3271320e+02, 1.8824100e+02, 7.5193000e-01, 3.2174000e-02,\n",
       "        6.0325600e-01, 6.3140000e-03, 1.7502600e-01, 1.7451800e-01,\n",
       "        5.8014000e-02, 5.7150000e-02]),\n",
       " array([8.31628381e+02, 7.27101314e+04, 3.92534794e+03, 0.00000000e+00,\n",
       "        1.48807220e-01, 0.00000000e+00, 9.21350214e-01, 0.00000000e+00,\n",
       "        3.58668606e-01, 1.00789244e-01, 1.41421356e-02, 0.00000000e+00,\n",
       "        3.24692293e-01, 2.06863623e-01, 3.46352410e-02, 2.82757830e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.46236878e-02, 2.13178059e+02,\n",
       "        2.46434686e+02, 3.79549677e-01, 3.79629215e-01, 2.30554301e-01,\n",
       "        2.31936410e-01, 3.87180002e-01, 8.02464573e-02, 1.43265096e-01,\n",
       "        6.41616855e+01, 1.05903981e+02, 4.10272543e-01, 1.14410103e-01,\n",
       "        4.80485433e-01, 3.89247535e-02, 3.79160483e-01, 3.79345157e-01,\n",
       "        2.30229270e-01, 2.29690420e-01]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the numerical columns\n",
    "\n",
    "i = 0\n",
    "means = np.zeros(len(clean_X.columns))\n",
    "devstd = np.zeros(len(clean_X.columns))\n",
    "# Calculate mean and variance for each column\n",
    "for column in clean_X.columns:\n",
    "    means[i] = float(clean_X.select(mean(column)).head()[0])\n",
    "    devstd[i] = float(clean_X.select(stddev(column)).head()[0])\n",
    "    i = i+1\n",
    "\n",
    "# norm_X = clean_X\n",
    "means, devstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO BE NORMALIZED!!\n",
    "\n",
    "# Step 0: Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for the distance between the cluster centers and the pandas dataframe\n",
    "def distance(xrow,broadC):\n",
    "    '''Distance between a dataframe.row\n",
    "    and the broadcasted list of centers\n",
    "    in the form of dataframe.row:\n",
    "    \n",
    "    broadC = sc.broadcast(center_rows)\n",
    "    xrow = clean_X.collect()[1]\n",
    "    '''\n",
    "    x = np.array(xrow)\n",
    "    centers = broadC.value\n",
    "    the_ds = np.zeros(len(centers))\n",
    "    \n",
    "    for c in range(len(centers)):\n",
    "        c_array = np.array(centers[c])\n",
    "        dist2 = np.linalg.norm(x - c_array)**2\n",
    "        the_ds[c] = dist2\n",
    "        \n",
    "    return np.min(the_ds)\n",
    "\n",
    "# Define the function for the logarithm of the cost phi\n",
    "def phi(df,centers ):\n",
    "    '''logarithm of the cost phi'''\n",
    "    return np.log( df.rdd.map(lambda row: distance(row,centers)).reduce(lambda x,y: x + y) )\n",
    "\n",
    "# Is this reasonable?? --> maybe we should cast it to int ?\n",
    "def evaluate_l(log_phi, k):\n",
    "    return k/log_phi\n",
    "\n",
    "# Function to select a row based on its probability\n",
    "def select_row(x):\n",
    "    if x > np.random.uniform(low = 0, high = 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is NOT $\\Phi$. This is $log(\\Phi)$. Pay attention budeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Choose a random sample from the dataset\n",
    "This is the required step to begin the algorithm (doesn't need to be parallelized, since it is a select task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the first sample randomly: select the random row\n",
    "random_n = [np.random.randint(0, n_rows)]\n",
    "\n",
    "# Define a function that is able to select the single row in the dataframe\n",
    "def getrows(df, rownums=None): # copied from the internet\n",
    "    return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: x[0])\n",
    "random_sample = getrows(clean_X, random_n).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting the row over the workers\n",
    "bCent = sc.broadcast(random_sample)\n",
    "\n",
    "# To show the content of the broadcast:\n",
    "# b.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Initial cost\n",
    "Then we evaluate the cost function (sum of the squares after the first selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial cost\n",
    "initial_cost = phi(clean_X, bCent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.5: evaluate number of iterations\n",
    "\n",
    "After having evaluated $\\log \\phi$, we find a number of iterations which is of the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(initial_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = int(initial_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: For loop\n",
    "Implement the for loop in order to evaluate probabilities and choose new centers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the log(phi) steps\n",
    "# for i in range(int(initial_cost))\n",
    "phi_iter = initial_cost\n",
    "l = evaluate_l(phi_iter, k)\n",
    "\n",
    "#Add initial probabilities\n",
    "#probabilities = clean_X.rdd.map(lambda row: np.exp(np.log(distance(row,bCent))-phi_iter)*l)\n",
    "\n",
    "#clean_X_p = clean_X.withColumn('probabilities', col(probabilities)) \n",
    "\n",
    "#distance = (clean_X.select(columns)\n",
    " #                      .withColumn('initial_cost', sum((col(colname)-random_sample[0][colname])**2 for colname in colnames))\n",
    "  #             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235301866565343"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve RDD 892\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:474)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:565)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:533)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n"
     ]
    }
   ],
   "source": [
    "clean_X.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < n_iter or len(bCent.value) < k:\n",
    "    '''\n",
    "    Nel ciclo for:\n",
    "        - Evaluate for each row l * d()^2 / phi\n",
    "        - Sample with that probability\n",
    "        - Broadcast centers to nodes\n",
    "        - Evaluate new cost\n",
    "        \n",
    "    Ricordiamoci che distance è già al quadrato e che phi è il logaritmo\n",
    "    '''\n",
    "\n",
    "    # Evaluate the probability and select the new rows\n",
    "    #probabilities = clean_X.rdd.map(lambda row: np.exp(np.log(distance(row,bCent))-phi_iter)*l)\n",
    "    new_rows = clean_X.rdd\\\n",
    "    .filter(lambda row: select_row(np.exp(np.log(distance(row,bCent))-phi_iter)*l)).collect()\n",
    "    \n",
    "    # Update the broadcast\n",
    "    bCent = sc.broadcast(bCent.value + new_rows)\n",
    "    \n",
    "    # Evaluate new cost\n",
    "    phi_iter =  phi(clean_X, bCent)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.912637325607122"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(duration=0, src_bytes=520, dst_bytes=0, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=0, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=511, srv_count=511, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=255, dst_host_srv_count=255, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=1.0, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0),\n",
       " Row(duration=5049, src_bytes=5133876, dst_bytes=0, land=0, wrong_fragment=0, urgent=0, hot=5, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=1, srv_count=1, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=4, dst_host_srv_count=34, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=1.0, dst_host_srv_diff_host_rate=0.15, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0),\n",
       " Row(duration=37, src_bytes=446, dst_bytes=184073, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=1, srv_count=1, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=69, dst_host_srv_count=11, dst_host_same_srv_rate=0.16, dst_host_diff_srv_rate=0.06, dst_host_same_src_port_rate=0.01, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0),\n",
       " Row(duration=0, src_bytes=155, dst_bytes=31614, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=3, srv_count=3, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=255, dst_host_srv_count=255, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=0.0, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0),\n",
       " Row(duration=0, src_bytes=54540, dst_bytes=8314, land=0, wrong_fragment=0, urgent=0, hot=2, num_failed_logins=0, logged_in=1, num_compromised=1, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=5, srv_count=6, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.17, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.33, dst_host_count=255, dst_host_srv_count=255, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=0.0, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.05, dst_host_srv_rerror_rate=0.05),\n",
       " Row(duration=0, src_bytes=232, dst_bytes=9171, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=4, srv_count=4, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=7, dst_host_srv_count=255, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=0.14, dst_host_srv_diff_host_rate=0.05, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0),\n",
       " Row(duration=0, src_bytes=252, dst_bytes=81061, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=2, srv_count=2, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=83, dst_host_srv_count=255, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=0.01, dst_host_srv_diff_host_rate=0.04, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0),\n",
       " Row(duration=0, src_bytes=314, dst_bytes=7333, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=14, srv_count=20, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.2, dst_host_count=255, dst_host_srv_count=255, dst_host_same_srv_rate=1.0, dst_host_diff_srv_rate=0.0, dst_host_same_src_port_rate=0.0, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0),\n",
       " Row(duration=31401, src_bytes=1, dst_bytes=0, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=0, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=2, srv_count=2, serror_rate=0.0, srv_serror_rate=0.0, rerror_rate=1.0, srv_rerror_rate=1.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=255, dst_host_srv_count=2, dst_host_same_srv_rate=0.01, dst_host_diff_srv_rate=0.82, dst_host_same_src_port_rate=1.0, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.0, dst_host_rerror_rate=1.0, dst_host_srv_rerror_rate=1.0),\n",
       " Row(duration=0, src_bytes=33580, dst_bytes=0, land=0, wrong_fragment=0, urgent=0, hot=0, num_failed_logins=0, logged_in=1, num_compromised=0, root_shell=0, su_attempted=0, num_root=0, num_file_creations=0, num_shells=0, num_access_files=0, num_outbound_cmds=0, is_host_login=0, is_guest_login=0, count=17, srv_count=17, serror_rate=0.06, srv_serror_rate=0.06, rerror_rate=0.0, srv_rerror_rate=0.0, same_srv_rate=1.0, diff_srv_rate=0.0, srv_diff_host_rate=0.0, dst_host_count=255, dst_host_srv_count=103, dst_host_same_srv_rate=0.4, dst_host_diff_srv_rate=0.02, dst_host_same_src_port_rate=0.4, dst_host_srv_diff_host_rate=0.0, dst_host_serror_rate=0.0, dst_host_srv_serror_rate=0.01, dst_host_rerror_rate=0.0, dst_host_srv_rerror_rate=0.0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bCent.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Select a subset of the possible centroids using k-means ++\n",
    "\n",
    "Using kmeans ++:\n",
    "\n",
    "Algorithm 1 k-means++(k) initialization.\n",
    "1: C ← sample a point uniformly at random from X\n",
    "2: while |C| < k do\n",
    "2\n",
    "3:\n",
    "Sample x ∈ X with probability dφX(x,C)\n",
    "(C)\n",
    "4:\n",
    "C ← C ∪ {"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Prendere la lista dei centroidi e farla diventare un distributed dataset\n",
    "- Fare una NUOVA lista di centroidi \n",
    "- for i in range(k):\n",
    "    pesca un singolo dato con probabilità d(x)/phi --> come fare?\n",
    "    aggiungilo alla lista\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "    - Capire come scegliere l\n",
    "    - Fare la normalizzazione dei dati (se la facciamo)\n",
    "    - Capire se abbiamo ottimizzato nel modo giusto\n",
    "    - Implementare tutto k means (optional)\n",
    "    - Creare un file gemello con un dataframe visualizzabile e vedere se ha senso\n",
    "    - Iniziare a fare i benchmark su cloud veneto\n",
    "    - Grafici etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Initial cost (OLD VERSION)\n",
    "Then we evaluate the cost function (sum of the squares after the first selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the name and type of the relevant columns\n",
    "coltypes = spark_X[[item[0] for item in spark_X.dtypes if item[1].startswith('double')]].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then make a list of the names\n",
    "columns = list(col(coltypes[i][0]) for i in range(len(coltypes)))\n",
    "colnames = list(coltypes[i][0] for i in range(len(coltypes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check that the columns are correctly selected\n",
    "spark_X.select(columns).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column with the initial calue of the error (to be updated throughout the program)\n",
    "initial_cost = (spark_X.select(columns)\n",
    "                       .withColumn('initial_cost', sum((col(colname)-random_sample[0][colname])**2 for colname in colnames))\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if the evaluation of the squared errors works (TO BE DELETED)\n",
    "initial_cost.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the total error (that will define the number of for loops done in the search)\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "# phi = initial_cost.select(sum(initial_cost.initial_cost)).show()\n",
    "\n",
    "phi = initial_cost.select(sum(initial_cost.initial_cost)).head()[0]\n",
    "print(phi)\n",
    "# IS IT A GOOD VALUE?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: updating loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop worker and master\n",
    "Stop the running Spark context (sc) and Spark session (spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use `docker compose down` to stop and clear all running containers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
