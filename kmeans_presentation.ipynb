{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPD-B: Pyspark implementation of kmeans || - kmeans++ and kmeans \n",
    "### Antonio Feltrin (2097126), Giosu√® Sardo Infirri (2094560), Simone Toso (2095484)\n",
    "\n",
    "In this project we will implement the ```kmeans||```, ```kmeans++``` and ```kmeans``` algorithms in PySpark as described in Bahmani's paper. We will use the ```kddCup99``` dataset as a testing ground.\n",
    "\n",
    "The overall code will follow the procedure presented in the paper:\n",
    " - ```kmeans||```:  algorithm for the selection of possible initial centroids. It heavily relies on oversampling and will therefore pick on average more candidate centers than desired.\n",
    " - ```kmeans++```: used to select $k$ initial centroids out of the candidates proposed by ```kmeans||```\n",
    " - ```kmeans```: final algorithm for clusterization starting from the centroids obtained with ```kmeans++```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark context initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/17 08:45:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://10.67.22.124:7077\")\\\n",
    "    .appName(\"prova iniziale\")\\\n",
    "    .config(\"spark.executor.memory\", \"1g\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.67.22.124:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7c5c300d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.67.22.124:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://10.67.22.124:7077 appName=PySparkShell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a spark context\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.datasets \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.functions import stddev\n",
    "from pyspark.sql.functions import rand\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import least\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import udf, array\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "from operator import add\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "Here we set the various hyperparameters. \n",
    "\n",
    "- ```k``` is the number of centroids we want to obtain\n",
    "- ```len_df``` is the number of rows considered out of the whole dataset. The maximum value we consider is 494 021, corresponding to 10% of the entire dataset (note that the ```fetch_kddcup99()``` command takes automatically 10% of the dataset if not specified otherwise).\n",
    "- ```G``` is used to evaluate the oversampling factor ```l```. In particular we will have $l = G\\cdot \\frac{k}{\\log \\phi}$, where $\\phi$ is the initial cost. We expect that, after the implementation of ```kmeans||```, we will have around $k\\cdot G$ possible centroids. The implementation of ```kmeans++``` will select $k$ centroids out of these possible candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "k = 140\n",
    "G = 3 \n",
    "len_df = 494_021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and create a Spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import the dataset and select randomly ```len_df``` rows. This will be the dataframe we will work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 1.57 s, total: 1min 21s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "spark_X = spark.createDataFrame(sklearn.datasets.fetch_kddcup99(percent10 = True, as_frame = True)['frame']\\\n",
    "                                .iloc[random.sample(range(0, len_df), len_df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_X = spark_X.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_X.rdd.getNumPartitions()\n",
    "#spark_X = spark_X.repartition(4) # We use repartition and coalesce during benchmarking to choose the number of partitions\n",
    "#spark_X = spark_X.coalesce(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of partitions\n",
    "spark_X.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that is able to extract a single row from the dataframe\n",
    "def getrows(df, rownums=None):\n",
    "    return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: x[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the non-numerical values\n",
    "col_type = np.array(spark_X.dtypes)\n",
    "types = col_type[:,1] \n",
    "colnames = col_type[:,0]\n",
    "clean_X = spark_X.select([col(colnames[i]) for i in range(len(colnames)) if not types[i] == 'binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the number of rows and columns in the dataframe\n",
    "n_rows = len_df\n",
    "n_cols = len(getrows(clean_X, rownums=[0]).collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the two schemas to check that the non-numerical variables were removed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_X.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: long (nullable = true)\n",
      " |-- protocol_type: binary (nullable = true)\n",
      " |-- service: binary (nullable = true)\n",
      " |-- flag: binary (nullable = true)\n",
      " |-- src_bytes: long (nullable = true)\n",
      " |-- dst_bytes: long (nullable = true)\n",
      " |-- land: long (nullable = true)\n",
      " |-- wrong_fragment: long (nullable = true)\n",
      " |-- urgent: long (nullable = true)\n",
      " |-- hot: long (nullable = true)\n",
      " |-- num_failed_logins: long (nullable = true)\n",
      " |-- logged_in: long (nullable = true)\n",
      " |-- num_compromised: long (nullable = true)\n",
      " |-- root_shell: long (nullable = true)\n",
      " |-- su_attempted: long (nullable = true)\n",
      " |-- num_root: long (nullable = true)\n",
      " |-- num_file_creations: long (nullable = true)\n",
      " |-- num_shells: long (nullable = true)\n",
      " |-- num_access_files: long (nullable = true)\n",
      " |-- num_outbound_cmds: long (nullable = true)\n",
      " |-- is_host_login: long (nullable = true)\n",
      " |-- is_guest_login: long (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      " |-- srv_count: long (nullable = true)\n",
      " |-- serror_rate: double (nullable = true)\n",
      " |-- srv_serror_rate: double (nullable = true)\n",
      " |-- rerror_rate: double (nullable = true)\n",
      " |-- srv_rerror_rate: double (nullable = true)\n",
      " |-- same_srv_rate: double (nullable = true)\n",
      " |-- diff_srv_rate: double (nullable = true)\n",
      " |-- srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_count: long (nullable = true)\n",
      " |-- dst_host_srv_count: long (nullable = true)\n",
      " |-- dst_host_same_srv_rate: double (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_serror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
      " |-- dst_host_rerror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
      " |-- labels: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_X.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans|| - step 0: Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Define the function for the squared distance between the cluster centers and the pandas dataframe (no more used)\n",
    "def distance(xrow, centers, num_cols=n_cols):\n",
    "    x = np.array(xrow)[:num_cols]\n",
    "    the_ds = np.zeros(len(centers))\n",
    "    \n",
    "    for c in range(len(centers)):\n",
    "        c_array = np.array(centers[c])[:num_cols]\n",
    "        dist2 = np.linalg.norm(x - c_array)**2\n",
    "        the_ds[c] = dist2\n",
    "        \n",
    "    return np.min(the_ds)\n",
    "\n",
    "# Euclidean distance between two rows (limited to the first n_cols)\n",
    "def euclid(xrow0, xrow1, num_cols = n_cols):\n",
    "    return np.linalg.norm( np.array(xrow0[0:num_cols]) - np.array(xrow1[0:num_cols]) )\n",
    "\n",
    "# Formula to evaluate the oversamping factor with the pre-factor G\n",
    "def evaluate_l(log_phi, k, G):\n",
    "    return G * k/log_phi # G = over-oversampling factor\n",
    "\n",
    "# Function to select a row based on its probability\n",
    "def select_row(x):\n",
    "    if x > np.random.uniform(low = 0, high = 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans|| - step 1. First sample and initial cost\n",
    "To start things off, we randomly choose the first centroid and evaluate the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Choose the first sample randomly: select the random row\n",
    "random_n = [np.random.randint(0, n_rows)]\n",
    "random_sample = getrows(clean_X, random_n).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Names of the dataset's columns.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m colnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(clean_X\u001b[38;5;241m.\u001b[39mdtypes[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mclean_X\u001b[49m\u001b[38;5;241m.\u001b[39mdtypes)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_X' is not defined"
     ]
    }
   ],
   "source": [
    "# Names of the dataset's columns.\n",
    "colnames = list(clean_X.dtypes[i][0] for i in range(len(clean_X.dtypes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add the colunm to keep the minimum distance between each point and the closest center\n",
    "clean_X = (clean_X.select('*')\n",
    "           .withColumn('minimum_cost', sum((col(colname)-random_sample[0][colname])**2 for colname in colnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.71877145069312"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial cost\n",
    "initial_cost = np.log(clean_X.agg({\"minimum_cost\": \"sum\"}).collect()[0][0])\n",
    "initial_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add the \"minimum_cost\" column to the center (with value 0), to avoid having different lengths in the final center list.\n",
    "temp = random_sample[0].asDict()\n",
    "temp[\"minimum_cost\"] = 0.\n",
    "random_sample[0] = Row(**temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to avoid having the centers scattered across multiple nodes, so we chose to broadcast the list of selected centers. If we didn't do it, each computation of euclidean distance would have been very heavy on the network communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Broadcasting the row over the workers\n",
    "bCent = sc.broadcast(random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans|| - step 3: Loop implementation\n",
    "We now evaluate the number of iterations we want to cycle through and implement the for loop. In each iteration we will independently select centers based on their distance from those already selected.\n",
    "\n",
    "In the loop, we evaluate the distance from the newly selected centers only and compare it to the previous minimum distance. This way, we avoid computing multiple times the distance from centers which we already know are not the closest ones from a given row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_iterations = log(phi)\n",
    "n_iter = int(initial_cost)\n",
    "n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.314653046656463"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize cost \n",
    "phi_iter = initial_cost\n",
    "\n",
    "#Evaluate oversampling factor\n",
    "l = evaluate_l(phi_iter, k, G)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.3021507263183594 seconds ---\n",
      "--- 0.019869565963745117 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.0087106227874756 seconds ---\n",
      "\n",
      " at iteration 1 , #values:  2  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.8010632991790771 seconds ---\n",
      "--- 0.02894139289855957 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.651654958724976 seconds ---\n",
      "\n",
      " at iteration 2 , #values:  11  \n",
      "\n",
      "--- 0.7130675315856934 seconds ---\n",
      "--- 0.01677107810974121 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.560967683792114 seconds ---\n",
      "\n",
      " at iteration 3 , #values:  28  \n",
      "\n",
      "--- 0.7638812065124512 seconds ---\n",
      "--- 0.019711732864379883 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.5398359298706055 seconds ---\n",
      "\n",
      " at iteration 4 , #values:  41  \n",
      "\n",
      "--- 0.7120873928070068 seconds ---\n",
      "--- 0.029645919799804688 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 12.50135326385498 seconds ---\n",
      "\n",
      " at iteration 5 , #values:  63  \n",
      "\n",
      "--- 0.80338454246521 seconds ---\n",
      "--- 0.014749288558959961 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.033488750457764 seconds ---\n",
      "\n",
      " at iteration 6 , #values:  76  \n",
      "\n",
      "--- 0.8093929290771484 seconds ---\n",
      "--- 0.02459406852722168 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.922570705413818 seconds ---\n",
      "\n",
      " at iteration 7 , #values:  86  \n",
      "\n",
      "--- 0.8105731010437012 seconds ---\n",
      "--- 0.020987987518310547 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.072460412979126 seconds ---\n",
      "\n",
      " at iteration 8 , #values:  94  \n",
      "\n",
      "--- 0.8704545497894287 seconds ---\n",
      "--- 0.03604435920715332 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.470468044281006 seconds ---\n",
      "\n",
      " at iteration 9 , #values:  101  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.890662431716919 seconds ---\n",
      "--- 0.017138957977294922 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.223142623901367 seconds ---\n",
      "\n",
      " at iteration 10 , #values:  110  \n",
      "\n",
      "--- 0.8430938720703125 seconds ---\n",
      "--- 0.02824568748474121 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.190376043319702 seconds ---\n",
      "\n",
      " at iteration 11 , #values:  120  \n",
      "\n",
      "--- 0.9445655345916748 seconds ---\n",
      "--- 0.012666940689086914 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.702638149261475 seconds ---\n",
      "\n",
      " at iteration 12 , #values:  133  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.0273563861846924 seconds ---\n",
      "--- 0.028737783432006836 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.99812126159668 seconds ---\n",
      "\n",
      " at iteration 13 , #values:  140  \n",
      "\n",
      "--- 1.0069444179534912 seconds ---\n",
      "--- 0.015172243118286133 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.207391262054443 seconds ---\n",
      "\n",
      " at iteration 14 , #values:  152  \n",
      "\n",
      "--- 1.0210638046264648 seconds ---\n",
      "--- 0.007494688034057617 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.4544031620025635 seconds ---\n",
      "\n",
      " at iteration 15 , #values:  160  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.0767366886138916 seconds ---\n",
      "--- 0.00979161262512207 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.37482762336731 seconds ---\n",
      "\n",
      " at iteration 16 , #values:  170  \n",
      "\n",
      "--- 1.0891304016113281 seconds ---\n",
      "--- 0.0114898681640625 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6.844731569290161 seconds ---\n",
      "\n",
      " at iteration 17 , #values:  179  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.151904821395874 seconds ---\n",
      "--- 0.019900083541870117 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.77961802482605 seconds ---\n",
      "\n",
      " at iteration 18 , #values:  189  \n",
      "\n",
      "--- 1.1612231731414795 seconds ---\n",
      "--- 0.009702920913696289 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.744345664978027 seconds ---\n",
      "\n",
      " at iteration 19 , #values:  201  \n",
      "\n",
      "--- 1.243210792541504 seconds ---\n",
      "--- 0.02343297004699707 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 12.11919093132019 seconds ---\n",
      "\n",
      " at iteration 20 , #values:  221  \n",
      "\n",
      "--- 1.2077486515045166 seconds ---\n",
      "--- 0.028949260711669922 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.831791162490845 seconds ---\n",
      "\n",
      " at iteration 21 , #values:  227  \n",
      "\n",
      "--- 1.1989903450012207 seconds ---\n",
      "--- 0.0175168514251709 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.444331407546997 seconds ---\n",
      "\n",
      " at iteration 22 , #values:  240  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.2848546504974365 seconds ---\n",
      "--- 0.013524532318115234 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.95656681060791 seconds ---\n",
      "\n",
      " at iteration 23 , #values:  249  \n",
      "\n",
      "--- 1.285496711730957 seconds ---\n",
      "--- 0.013084888458251953 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.75012493133545 seconds ---\n",
      "\n",
      " at iteration 24 , #values:  261  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.4242756366729736 seconds ---\n",
      "--- 0.01563286781311035 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.232994556427002 seconds ---\n",
      "\n",
      " at iteration 25 , #values:  274  \n",
      "\n",
      "--- 1.3975632190704346 seconds ---\n",
      "--- 0.016738176345825195 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.550790786743164 seconds ---\n",
      "\n",
      " at iteration 26 , #values:  282  \n",
      "\n",
      "--- 1.485058307647705 seconds ---\n",
      "--- 0.0286257266998291 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.905394554138184 seconds ---\n",
      "\n",
      " at iteration 27 , #values:  292  \n",
      "\n",
      "--- 1.6279282569885254 seconds ---\n",
      "--- 0.006941795349121094 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.82502555847168 seconds ---\n",
      "\n",
      " at iteration 28 , #values:  302  \n",
      "\n",
      "--- 1.5473978519439697 seconds ---\n",
      "--- 0.01551675796508789 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.576607465744019 seconds ---\n",
      "\n",
      " at iteration 29 , #values:  311  \n",
      "\n",
      "--- 1.605872392654419 seconds ---\n",
      "--- 0.016425609588623047 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.730584859848022 seconds ---\n",
      "\n",
      " at iteration 30 , #values:  321  \n",
      "\n",
      "--- 1.6173851490020752 seconds ---\n",
      "--- 0.008423566818237305 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.12281322479248 seconds ---\n",
      "\n",
      " at iteration 31 , #values:  340  \n",
      "\n",
      "--- 1.7660374641418457 seconds ---\n",
      "--- 0.010366439819335938 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.834041595458984 seconds ---\n",
      "\n",
      " at iteration 32 , #values:  347  \n",
      "\n",
      "--- 1.8577003479003906 seconds ---\n",
      "--- 0.012343883514404297 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.143404960632324 seconds ---\n",
      "\n",
      " at iteration 33 , #values:  356  \n",
      "\n",
      "--- 1.8668835163116455 seconds ---\n",
      "--- 0.02301192283630371 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.766727209091187 seconds ---\n",
      "\n",
      " at iteration 34 , #values:  366  \n",
      "\n",
      "--- 1.9275741577148438 seconds ---\n",
      "--- 0.0177462100982666 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.805544137954712 seconds ---\n",
      "\n",
      " at iteration 35 , #values:  371  \n",
      "\n",
      "--- 2.050144672393799 seconds ---\n",
      "--- 0.02292919158935547 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.059290409088135 seconds ---\n",
      "\n",
      " at iteration 36 , #values:  382  \n",
      "\n",
      "--- 2.238307476043701 seconds ---\n",
      "--- 0.007734775543212891 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.896390199661255 seconds ---\n",
      "\n",
      " at iteration 37 , #values:  396  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.1909267902374268 seconds ---\n",
      "--- 0.008402585983276367 seconds ---\n"
     ]
    }
   ],
   "source": [
    "i = 0 # count iterations\n",
    "last_centers = 1 # how many centers were selected in the previous iteration. Initialized to 1\n",
    "\n",
    "while i < n_iter: \n",
    "\n",
    "        '''\n",
    "        Nel ciclo for:\n",
    "            - Evaluate for each row l * d()^2 / phi\n",
    "            - Sample with that probability\n",
    "            - Broadcast centers to nodes\n",
    "            - Evaluate new cost\n",
    "\n",
    "        '''\n",
    "\n",
    "        # Evaluate the probability and select the new center rows\n",
    "        mod_phi = l/np.exp(phi_iter) #Normalization factor to obtain selection probability \n",
    "        new_rows = clean_X.select('*').withColumn('random_number', rand(seed=int(time.time())))\\\n",
    "                          .filter(col('random_number') < col('minimum_cost')*mod_phi).drop('random_number').collect()\n",
    "        \n",
    "        # Update the broadcast with newest at the beginning\n",
    "        old_centers = bCent.value\n",
    "        bCent.destroy()\n",
    "        bCent = sc.broadcast(new_rows + old_centers)\n",
    "    \n",
    "        # Update the minimum distance\n",
    "        if len(new_rows) == 1:\n",
    "            clean_X = clean_X.select('*').\\\n",
    "                      withColumn('minimum_cost', least('minimum_cost', reduce(add, [(col(colname)-bCent.value[0][colname])**2 for colname in colnames]))).cache()\n",
    "\n",
    "        elif len(new_rows) > 1:\n",
    "            clean_X = clean_X.select('*').withColumn('dummy', least(*[reduce(add, [(col(colname)-bCent.value[center][colname])**2 for colname in colnames]) for center in range(len(new_rows))] )).\\\n",
    "                      withColumn('minimum_cost', least('minimum_cost', 'dummy')).\\\n",
    "                      drop('dummy').cache()\n",
    "\n",
    "        last_centers = len(bCent.value)\n",
    "\n",
    "        # Evaluate new cost\n",
    "        phi_iter = np.log(clean_X.agg({\"minimum_cost\": \"sum\"}).collect()[0][0])\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        print(\"\\n at iteration\", i ,\", #values: \",len(bCent.value), \" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Centers found: \", len(bCent.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans++ - step 0: Useful functions\n",
    "We define a few functions which will be useful in the following code. They allow us, given a certain ```Row```, to find the closest center and the minimum distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Find the closest center to a certain row\n",
    "def find_min_euclid(xrow, broadC):\n",
    "    distances = []\n",
    "    for i in range(len(broadC.value)):\n",
    "        distances.append(euclid(xrow, broadC.value[i]))\n",
    "    return distances.index(min(distances))\n",
    "\n",
    "# Find the minimum distance between row and centers\n",
    "def min_euclid(xrow, broadC):\n",
    "    distances = []\n",
    "    for i in range(len(broadC.value)):\n",
    "        distances.append(euclid(xrow, broadC.value[i])**2)\n",
    "    return min(distances).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Create a dataframe with the candidate centers\n",
    "dfCent = spark.createDataFrame(bCent.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dfCent.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans++ - step1: Evaluate weights\n",
    "\n",
    "The weight $w$ of a center is the number of points in ```clean_X``` which are closest to it than to any other center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampled_centers = dfCent.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "wx = clean_X.rdd.map(lambda row: (find_min_euclid(row,bCent), 1)).\\\n",
    "        reduceByKey(lambda x,y: x+y).\\\n",
    "        takeOrdered(over_sampled_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical note\n",
    "\n",
    "<em>Now we could have a problem. During the row sampling in the `kmeans||` process, it could happen that two identical rows (with indeces $i$ and $j$, $i<j$) are selected at the same loop iteration. This happens quite often if we have $G\\gg1$. This results in one of the two centroids not appearing in ```wx```: all rows closest to $j$ are redirected towards $i$, even $j$ itself. So wx has a vacancy: the sequence goes 1,2,3, ..., $i$, ..., $j-1$, $j+1$, ...  . In order to solve this issue, we manually add missing entries and set their value to 0. This implies that the \"twin\" center has zero probability to be selected. All of this kerfuffle is just due to prevent a size error in the `rows_prob@wx` product, some cells below this line.<em/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(wx)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "while counter < len(wx):\n",
    "    if wx[int(counter)][0] == counter:\n",
    "        counter += 1\n",
    "    else: \n",
    "        wx.insert(int(counter),(counter,0))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Take the weights and cast to float\n",
    "wx = (np.array(wx)[:,1]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Normalize weights\n",
    "wx /= np.sum(wx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans++ - step 2: Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Draw 1 random center\n",
    "first_index = np.random.choice(a=range(wx.shape[0]), size=1, p=wx) \n",
    "first_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "first_center = getrows(dfCent, first_index).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Adds the first center to the ultimate center broadcast\n",
    "bCent_ultimate = sc.broadcast(first_center)\n",
    "bCent_ultimate.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Define the total distance from other centers (minimum cost) over the chosen center\n",
    "dfCent = (dfCent.select('*')\n",
    "         .withColumn('minimum_cost', sum((col(colname)-first_center[0][colname])**2 for colname in colnames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminiamo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the total cost value\n",
    "#phi0 = np.log(dfCent.agg({\"minimum_cost\": \"sum\"}).collect()[0][0])\n",
    "#phi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ultimate_sample_n = len(bCent_ultimate.value)\n",
    "\n",
    "while ultimate_sample_n < k: #n_iter or len(bCent.value) < k:\n",
    "\n",
    "    # Evaluate the probability and select the new rows\n",
    "    rows_prob = np.array(dfCent.rdd\\\n",
    "                .map(lambda row: distance(row,bCent_ultimate.value)).collect())\n",
    "    \n",
    "    # Sample new weighted random center\n",
    "    another_index = np.random.choice(a=range(wx.shape[0]), size=1, p = rows_prob*wx/(rows_prob@wx) ) \n",
    "    another_center = getrows(dfCent, another_index).collect()\n",
    "    \n",
    "    # Update the broadcast\n",
    "    old_centers = bCent_ultimate.value\n",
    "    bCent_ultimate.destroy()    \n",
    "    bCent_ultimate = sc.broadcast(another_center + old_centers)\n",
    "\n",
    "    # For consistency reason:    \n",
    "    # Update minimum cost\n",
    "    #dfCent = dfCent.select('*').\\\n",
    "    #withColumn('minimum_cost', least('minimum_cost', sum((col(colname)-another_center[0][colname])**2 for colname in colnames) )).cache()\n",
    "    \n",
    "    # Evaluate new cost\n",
    "    #phi0 = np.log(dfCent.agg({\"minimum_cost\": \"sum\"}).collect()[0][0])\n",
    "    \n",
    "    ultimate_sample_n = len(bCent_ultimate.value)\n",
    "    print(\"i: \",ultimate_sample_n)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "# k means\n",
    "Finally, we implement ```kmeans``` on our dataset with the initial centroids obtained thus far. We stop when the relative variation of the cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X = clean_X.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the initial value of the cost function\n",
    "min_cost_udf = udf(lambda row: min_euclid(row, bCent_ultimate), FloatType())\n",
    "clean_X = clean_X.withColumn(\"minimum_cost\",min_cost_udf(array([col for col in colnames]))).persist()\n",
    "phi0 = clean_X.agg({\"minimum_cost\": \"sum\"}).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "phi1 = phi0\n",
    "still_different = True\n",
    "eps = 1e-4\n",
    "\n",
    "while still_different:\n",
    "\n",
    "    # Create the weights and switch to indexed dataframe\n",
    "    find_closest_udf = udf(lambda row: find_min_euclid(row, bCent_ultimate), IntegerType())\n",
    "    final_df = clean_X.withColumn(\"closest\", find_closest_udf(array([col for col in colnames]))).persist()\n",
    "\n",
    "    # Update new centers:\n",
    "    new_centers = final_df.groupBy('closest').agg(*[mean(c).alias(c) for c in colnames]).drop('closest').collect()\n",
    "    #bCent_ultimate.destroy()\n",
    "    bCent_ultimate = sc.broadcast(new_centers)\n",
    "\n",
    "    # Update the minimum cost function\n",
    "    min_cost_udf = udf(lambda row: min_euclid(row, bCent_ultimate), FloatType())\n",
    "    clean_X = clean_X.withColumn(\"minimum_cost\",min_cost_udf(array([col for col in colnames]))).persist()\n",
    "\n",
    "    # Evaluate new cost\n",
    "    phi1 = clean_X.agg({\"minimum_cost\": \"sum\"}).collect()[0][0]\n",
    "    print('Relative cost variation:', abs(phi1 - phi0)/phi0)\n",
    "    if abs(phi1 - phi0)/phi0 < eps:\n",
    "        still_different = False\n",
    "    else:\n",
    "        phi0 = phi1\n",
    "\n",
    "    n += 1\n",
    "\n",
    "    #Persist to avoid stack overflow\n",
    "    clean_X = clean_X.persist()\n",
    "\n",
    "print('It took', n, 'iterations to converge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "We plot the final centers, projecting on two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = \"dst_bytes\"\n",
    "dim2 = \"duration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_np = clean_X.select(dim1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_np = clean_X.select(dim2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(src_np[1:], dst_np[1:])\n",
    "\n",
    "for i in range(len(bCent_ultimate.value)):\n",
    "   plt.scatter(bCent_ultimate.value[i][dim1],bCent_ultimate.value[i][dim2],color='black', alpha = 0.5)\n",
    "#plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(np.exp(26.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('final time', time.time() - time0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- usare udf ovunque (fatto?)\n",
    "- persist/unpersist sui vari dataframe in giro per non intasare la memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop worker and master\n",
    "Stop the running Spark context (sc) and Spark session (spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# sc.stop()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
