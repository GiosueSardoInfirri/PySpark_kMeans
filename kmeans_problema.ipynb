{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k means ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/31 17:17:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# import the python libraries to create/connect to a Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# build a SparkSession \n",
    "#   connect to the master node on the port where the master node is listening (7077)\n",
    "#   declare the app name \n",
    "#   configure the executor memory to 512 MB\n",
    "#   either *connect* or *create* a new Spark Context\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\")\\\n",
    "    .appName(\"prova iniziale\")\\\n",
    "    .config(\"spark.executor.memory\", \"512m\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c311f107a004:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>prova iniziale</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8d4c24e700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c311f107a004:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>prova iniziale</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://spark-master:7077 appName=prova iniziale>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a spark context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# print its status\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.11.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn # to be run at the launch of \"docker compose up\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.datasets #va installato\n",
    "import time\n",
    "\n",
    "# from pyspark.sql.functions import sum\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import least\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.functions import stddev\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "k = 20\n",
    "G = 3 # Giosu factor\n",
    "len_df = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe directly from sklearn\n",
    "prova =  sklearn.datasets.fetch_kddcup99(percent10 = True, as_frame = True)\n",
    "X = prova.data\n",
    "\n",
    "# prova = sc.parallelize(sklearn.datasets.fetch_kddcup99(percent10 = True, as_frame = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494016</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>310</td>\n",
       "      <td>1881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494017</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>282</td>\n",
       "      <td>2286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494018</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>203</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494019</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>291</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494020</th>\n",
       "      <td>0</td>\n",
       "      <td>b'tcp'</td>\n",
       "      <td>b'http'</td>\n",
       "      <td>b'SF'</td>\n",
       "      <td>219</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494021 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration protocol_type  service   flag src_bytes dst_bytes land  \\\n",
       "0             0        b'tcp'  b'http'  b'SF'       181      5450    0   \n",
       "1             0        b'tcp'  b'http'  b'SF'       239       486    0   \n",
       "2             0        b'tcp'  b'http'  b'SF'       235      1337    0   \n",
       "3             0        b'tcp'  b'http'  b'SF'       219      1337    0   \n",
       "4             0        b'tcp'  b'http'  b'SF'       217      2032    0   \n",
       "...         ...           ...      ...    ...       ...       ...  ...   \n",
       "494016        0        b'tcp'  b'http'  b'SF'       310      1881    0   \n",
       "494017        0        b'tcp'  b'http'  b'SF'       282      2286    0   \n",
       "494018        0        b'tcp'  b'http'  b'SF'       203      1200    0   \n",
       "494019        0        b'tcp'  b'http'  b'SF'       291      1200    0   \n",
       "494020        0        b'tcp'  b'http'  b'SF'       219      1234    0   \n",
       "\n",
       "       wrong_fragment urgent hot  ... dst_host_count dst_host_srv_count  \\\n",
       "0                   0      0   0  ...              9                  9   \n",
       "1                   0      0   0  ...             19                 19   \n",
       "2                   0      0   0  ...             29                 29   \n",
       "3                   0      0   0  ...             39                 39   \n",
       "4                   0      0   0  ...             49                 49   \n",
       "...               ...    ...  ..  ...            ...                ...   \n",
       "494016              0      0   0  ...             86                255   \n",
       "494017              0      0   0  ...              6                255   \n",
       "494018              0      0   0  ...             16                255   \n",
       "494019              0      0   0  ...             26                255   \n",
       "494020              0      0   0  ...              6                255   \n",
       "\n",
       "       dst_host_same_srv_rate dst_host_diff_srv_rate  \\\n",
       "0                         1.0                    0.0   \n",
       "1                         1.0                    0.0   \n",
       "2                         1.0                    0.0   \n",
       "3                         1.0                    0.0   \n",
       "4                         1.0                    0.0   \n",
       "...                       ...                    ...   \n",
       "494016                    1.0                    0.0   \n",
       "494017                    1.0                    0.0   \n",
       "494018                    1.0                    0.0   \n",
       "494019                    1.0                    0.0   \n",
       "494020                    1.0                    0.0   \n",
       "\n",
       "       dst_host_same_src_port_rate dst_host_srv_diff_host_rate  \\\n",
       "0                             0.11                         0.0   \n",
       "1                             0.05                         0.0   \n",
       "2                             0.03                         0.0   \n",
       "3                             0.03                         0.0   \n",
       "4                             0.02                         0.0   \n",
       "...                            ...                         ...   \n",
       "494016                        0.01                        0.05   \n",
       "494017                        0.17                        0.05   \n",
       "494018                        0.06                        0.05   \n",
       "494019                        0.04                        0.05   \n",
       "494020                        0.17                        0.05   \n",
       "\n",
       "       dst_host_serror_rate dst_host_srv_serror_rate dst_host_rerror_rate  \\\n",
       "0                       0.0                      0.0                  0.0   \n",
       "1                       0.0                      0.0                  0.0   \n",
       "2                       0.0                      0.0                  0.0   \n",
       "3                       0.0                      0.0                  0.0   \n",
       "4                       0.0                      0.0                  0.0   \n",
       "...                     ...                      ...                  ...   \n",
       "494016                  0.0                     0.01                  0.0   \n",
       "494017                  0.0                     0.01                  0.0   \n",
       "494018                 0.06                     0.01                  0.0   \n",
       "494019                 0.04                     0.01                  0.0   \n",
       "494020                  0.0                     0.01                  0.0   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "494016                      0.0  \n",
       "494017                      0.0  \n",
       "494018                      0.0  \n",
       "494019                      0.0  \n",
       "494020                      0.0  \n",
       "\n",
       "[494021 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataframe (to be deleted for a bigger dataframe) (TO BE DELETED)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Spark dataframe\n",
    "And then acquire important informations about the dataframe: # columns, # rows, # partitions, the schema, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/spark-3.3.2-bin-hadoop3/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/bin/spark-3.3.2-bin-hadoop3/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# Create the spark dataframe with a smaller chunk of data (just to work easily)\n",
    "X_smaller = X.iloc[random.sample(range(1, len(X.index)), len_df)]\n",
    "spark_X = spark.createDataFrame(X_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of partitions the DataFrame is divided into the three workers yet\n",
    "spark_X.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that is able to select the single row in the dataframe\n",
    "def getrows(df, rownums=None): # copied from the internet\n",
    "    return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the non-numerical values in an easy way\n",
    "# clean_X = spark_X.select('*').drop('protocol_type', 'service', 'flag')\n",
    "# clean_X.printSchema()\n",
    "\n",
    "# Delete the non-numerical values in a reusable way\n",
    "col_type = np.array(spark_X.dtypes)\n",
    "types = col_type[:,1] \n",
    "colnames = col_type[:,0]\n",
    "clean_X = spark_X.select([col(colnames[i]) for i in range(len(colnames)) if not types[i] == 'binary'])\n",
    "# clean_X.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the numerical columns\n",
    "\n",
    "# i = 0\n",
    "# means = np.zeros(len(clean_X.columns))\n",
    "# devstd = np.zeros(len(clean_X.columns))\n",
    "# # Calculate mean and variance for each column\n",
    "# for column in clean_X.columns:\n",
    "#     means[i] = float(clean_X.select(mean(column)).head()[0])\n",
    "#     devstd[i] = float(clean_X.select(stddev(column)).head()[0])\n",
    "#     i = i+1\n",
    "\n",
    "# # norm_X = clean_X\n",
    "# means, devstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO BE NORMALIZED!!\n",
    "\n",
    "### This is NOT $\\Phi$. This is $log(\\Phi)$. Pay attention budeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/31 17:17:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = [ 10000 , 38 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:=======================================>                   (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the number of rows and columns in the dataframe\n",
    "n_rows = clean_X.count()\n",
    "n_cols = len(getrows(clean_X, rownums=[0]).collect()[0])\n",
    "print('shape = [',n_rows,',',n_cols,']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Choose a random sample from the dataset\n",
    "This is the required step to begin the algorithm (doesn't need to be parallelized, since it is a select task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the first sample randomly: select the random row\n",
    "random_n = [np.random.randint(0, n_rows)]\n",
    "random_sample = getrows(clean_X, random_n).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Initial cost\n",
    "Then we evaluate the cost function (sum of the squares after the first selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(clean_X.dtypes[i][0] for i in range(len(clean_X.dtypes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1: Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X = (clean_X.select('*')\n",
    "           .withColumn('minimum_cost', sum((col(colname)-random_sample[0][colname])**2 for colname in colnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(getrows(clean_X, rownums=[0]).collect()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED FUNCTIONS\n",
    "\n",
    "# Define the function for the distance between the cluster centers and the pandas dataframe\n",
    "def distance(xrow, centers, num_cols=n_cols): #, gimme_argmin=False):\n",
    "    '''Distance between a dataframe.row\n",
    "    and the broadcasted value list of centers\n",
    "    in the form of dataframe.row.value:\n",
    "    \n",
    "    broadC = sc.broadcast(center_rows).value\n",
    "    xrow = clean_X.collect()[1]\n",
    "    '''\n",
    "    x = np.array(xrow)[:num_cols]\n",
    "    the_ds = np.zeros(len(centers))\n",
    "    \n",
    "    for c in range(len(centers)):\n",
    "        c_array = np.array(centers[c])[:num_cols]\n",
    "        dist2 = np.linalg.norm(x - c_array)**2\n",
    "        the_ds[c] = dist2\n",
    "            \n",
    "    #if gimme_argmin: return np.argmin(the_ds)        \n",
    "    return float(np.min(the_ds))\n",
    "\n",
    "def find_closest_center(xrow,broadC, num_cols=n_cols):\n",
    "    '''Distance between a dataframe.row\n",
    "    and the broadcasted list of centers\n",
    "    in the form of dataframe.row:\n",
    "    \n",
    "    broadC = sc.broadcast(center_rows)\n",
    "    xrow = clean_X.collect()[1]\n",
    "    '''\n",
    "    x = np.array(xrow)[:num_cols]\n",
    "    centers = broadC.value\n",
    "    the_ds = np.zeros(len(centers))\n",
    "    \n",
    "    for c in range(len(centers)):\n",
    "        c_array = np.array(centers[c])[:num_cols]\n",
    "        dist2 = np.linalg.norm(x - c_array)**2\n",
    "        the_ds[c] = dist2\n",
    "        \n",
    "    return np.argmin(the_ds)\n",
    "\n",
    "def evaluate_l(log_phi, k, G):\n",
    "    return G * k/log_phi # G = over-oversampling factor\n",
    "\n",
    "# Function to select a row based on its probability\n",
    "def select_row(x):\n",
    "    if x > np.random.uniform(low = 0, high = 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def if_greater(xrow, centers):\n",
    "    return min(distance(xrow, centers, 38), xrow.__getitem__('minimum_cost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.603731043232557"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial cost\n",
    "# initial_cost = phi(clean_X, bCent)\n",
    "initial_cost = np.log(clean_X.agg({\"minimum_cost\": \"sum\"}).collect()[0][0])\n",
    "# initial_cost = clean_X.select(['minimum_cost']).rdd.map(lambda x : x).reduce(sum)\n",
    "initial_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "temp = random_sample[0].asDict()\n",
    "temp[\"minimum_cost\"] = 0.0\n",
    "random_sample[0] = Row(**temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting the row over the workers\n",
    "bCent = sc.broadcast(random_sample)\n",
    "\n",
    "# To show the content of the broadcast: b.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.5: evaluate number of iterations\n",
    "\n",
    "After having evaluated $\\log \\phi$, we find a number of iterations which is of the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = int(initial_cost)\n",
    "n_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: For loop\n",
    "Implement the for loop in order to evaluate probabilities and choose new centers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8985100182608996"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_iter = initial_cost\n",
    "l = evaluate_l(phi_iter, k, G)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_X.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bCent.value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# i = 0\n",
    "# start_time = time.time()\n",
    "\n",
    "# while i < n_iter or len(bCent.value) < k:\n",
    "# # while i < 1:\n",
    "#     '''\n",
    "#     Nel ciclo for:\n",
    "#         - Evaluate for each row l * d()^2 / phi\n",
    "#         - Sample with that probability\n",
    "#         - Broadcast centers to nodes\n",
    "#         - Evaluate new cost\n",
    "        \n",
    "#     Ricordiamoci che distance è già al quadrato e che phi è il logaritmo\n",
    "#     '''\n",
    "\n",
    "#     # Evaluate the probability and select the new rows\n",
    "#     #probabilities = clean_X.rdd.map(lambda row: np.exp(np.log(distance(row,bCent))-phi_iter)*l)\n",
    "#     new_rows = clean_X.rdd\\\n",
    "#     .filter(lambda row: select_row(np.exp(np.log(distance(row,bCent))-phi_iter)*l)).collect()\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Update the broadcast\n",
    "#     bCent = sc.broadcast(bCent.value + new_rows)\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Evaluate new cost\n",
    "#     phi_iter =  phi(clean_X, bCent)\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     i += 1\n",
    "#     print(\"\\n at iteration\", i ,\", #values: \",len(bCent.value), \" \\n\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best to ship this function to all executors in case of huge datasets\n",
    "def chooseNewDistance(groupedRows, index):\n",
    "\n",
    "    res = []\n",
    "    \n",
    "    for row in groupedRows:\n",
    "        #calcola nuova distanza da centri --> vedi se è minore dell'ultima entrata --> sostituisci se serve\n",
    "        new_distance = distance(row, bCent.value[index: ], len(bCent.value[-1])-1)\n",
    "        best_distance = new_distance\n",
    "        if row.minimum_cost < best_distance:\n",
    "            best_distance = row.minimum_cost\n",
    "\n",
    "        res.append([item for item in row][0:n_cols] + [best_distance])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random bullshit  go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_sample2 = getrows(clean_X, [42]).collect()\n",
    "#random_sample2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bCent2 = sc.broadcast(bCent.value + random_sample2)\n",
    "#len(bCent2.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_dist = clean_X.rdd.groupBy(lambda gk: 1).\\\n",
    "#    map(lambda r: distance(r, bCent2.value)).values()\n",
    "\n",
    "#new_dist.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dum_list = ( sum((col(colname)-bCent2.value[c][colname])**2\\\n",
    "#      for colname in colnames) for c in range(len(bCent2.value)))\n",
    "\n",
    "#dum_list.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_X = clean_X.withColumn('new distance', min( sum((col(colname)-bCent2.value[c][colname])**2 for colname in colnames)\\\n",
    " #                                               for c in range(len(bCent2.value))))\n",
    "    #.withColumn('minimum_cost', sum((col(colname)-random_sample[0][colname])**2 for colname in colnames)))\n",
    "#clean_X.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Optimized' loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.6684951782226562 seconds ---\n",
      "--- 0.009012460708618164 seconds ---\n",
      "--- 3.310877561569214 seconds ---\n",
      "\n",
      " at iteration 1 , #values:  5  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:>                                                         (0 + 3) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.3766534328460693 seconds ---\n",
      "--- 0.08199715614318848 seconds ---\n",
      "--- 2.093325138092041 seconds ---\n",
      "\n",
      " at iteration 2 , #values:  6  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.594566822052002 seconds ---\n",
      "--- 0.008661985397338867 seconds ---\n",
      "--- 1.6670961380004883 seconds ---\n",
      "\n",
      " at iteration 3 , #values:  7  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.468034029006958 seconds ---\n",
      "--- 0.012346029281616211 seconds ---\n",
      "--- 1.6195857524871826 seconds ---\n",
      "\n",
      " at iteration 4 , #values:  8  \n",
      "\n",
      "--- 1.3109948635101318 seconds ---\n",
      "--- 0.015079021453857422 seconds ---\n",
      "--- 2.060483455657959 seconds ---\n",
      "\n",
      " at iteration 5 , #values:  9  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 39:===================>                                      (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.2447597980499268 seconds ---\n",
      "--- 0.019802331924438477 seconds ---\n",
      "--- 1.9153330326080322 seconds ---\n",
      "\n",
      " at iteration 6 , #values:  10  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 43:======================================>                   (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.2369897365570068 seconds ---\n",
      "--- 0.006741046905517578 seconds ---\n",
      "--- 1.7945849895477295 seconds ---\n",
      "\n",
      " at iteration 7 , #values:  11  \n",
      "\n",
      "--- 1.3798332214355469 seconds ---\n",
      "--- 0.017128467559814453 seconds ---\n",
      "--- 2.045921802520752 seconds ---\n",
      "\n",
      " at iteration 8 , #values:  12  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.7562546730041504 seconds ---\n",
      "--- 0.03276515007019043 seconds ---\n",
      "--- 2.2539114952087402 seconds ---\n",
      "\n",
      " at iteration 9 , #values:  13  \n",
      "\n",
      "--- 1.5526373386383057 seconds ---\n",
      "--- 0.014457941055297852 seconds ---\n",
      "--- 2.027837038040161 seconds ---\n",
      "\n",
      " at iteration 10 , #values:  14  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 59:======================================>                   (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.6289777755737305 seconds ---\n",
      "--- 0.01403045654296875 seconds ---\n",
      "--- 1.8699169158935547 seconds ---\n",
      "\n",
      " at iteration 11 , #values:  15  \n",
      "\n",
      "--- 1.4335174560546875 seconds ---\n",
      "--- 0.008494138717651367 seconds ---\n",
      "--- 1.874457597732544 seconds ---\n",
      "\n",
      " at iteration 12 , #values:  16  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 67:======================================>                   (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.5808048248291016 seconds ---\n",
      "--- 0.01509857177734375 seconds ---\n",
      "--- 2.090745449066162 seconds ---\n",
      "\n",
      " at iteration 13 , #values:  17  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 71:===================>                                      (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.5199174880981445 seconds ---\n",
      "--- 0.009657621383666992 seconds ---\n",
      "--- 2.119098424911499 seconds ---\n",
      "\n",
      " at iteration 14 , #values:  18  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 75:>                                                         (0 + 3) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.7205979824066162 seconds ---\n",
      "--- 0.024686098098754883 seconds ---\n",
      "--- 2.1491832733154297 seconds ---\n",
      "\n",
      " at iteration 15 , #values:  19  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 79:===================>                                      (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.8472614288330078 seconds ---\n",
      "--- 0.010131359100341797 seconds ---\n",
      "--- 2.1327857971191406 seconds ---\n",
      "\n",
      " at iteration 16 , #values:  20  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 83:===================>                                      (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.8831920623779297 seconds ---\n",
      "--- 0.011404991149902344 seconds ---\n",
      "--- 1.6430673599243164 seconds ---\n",
      "\n",
      " at iteration 17 , #values:  21  \n",
      "\n",
      "--- 2.0844316482543945 seconds ---\n",
      "--- 0.010019779205322266 seconds ---\n",
      "--- 2.4207472801208496 seconds ---\n",
      "\n",
      " at iteration 18 , #values:  22  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 91:======================================>                   (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.8917653560638428 seconds ---\n",
      "--- 0.008872032165527344 seconds ---\n",
      "--- 2.448990821838379 seconds ---\n",
      "\n",
      " at iteration 19 , #values:  23  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 95:===================>                                      (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.1648550033569336 seconds ---\n",
      "--- 0.005900859832763672 seconds ---\n",
      "--- 2.5417463779449463 seconds ---\n",
      "\n",
      " at iteration 20 , #values:  24  \n",
      "\n",
      "--- 1.9768097400665283 seconds ---\n",
      "--- 0.021481990814208984 seconds ---\n",
      "--- 2.546410322189331 seconds ---\n",
      "\n",
      " at iteration 21 , #values:  25  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 103:>                                                        (0 + 3) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.0908572673797607 seconds ---\n",
      "--- 0.012673377990722656 seconds ---\n",
      "--- 2.8346924781799316 seconds ---\n",
      "\n",
      " at iteration 22 , #values:  26  \n",
      "\n",
      "--- 2.05861759185791 seconds ---\n",
      "--- 0.02800893783569336 seconds ---\n",
      "--- 2.419043779373169 seconds ---\n",
      "\n",
      " at iteration 23 , #values:  27  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 111:======================================>                  (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.2459263801574707 seconds ---\n",
      "--- 0.01041865348815918 seconds ---\n",
      "--- 3.7348439693450928 seconds ---\n",
      "\n",
      " at iteration 24 , #values:  28  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 115:===================>                                     (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.748196840286255 seconds ---\n",
      "--- 0.01207733154296875 seconds ---\n",
      "--- 2.818716049194336 seconds ---\n",
      "\n",
      " at iteration 25 , #values:  29  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 119:>                                                        (0 + 3) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.6500797271728516 seconds ---\n",
      "--- 0.043766021728515625 seconds ---\n",
      "--- 2.8982126712799072 seconds ---\n",
      "\n",
      " at iteration 26 , #values:  30  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 123:======================================>                  (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.29988694190979 seconds ---\n",
      "--- 0.031096458435058594 seconds ---\n",
      "--- 2.7865500450134277 seconds ---\n",
      "\n",
      " at iteration 27 , #values:  31  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 127:===================>                                     (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.23783802986145 seconds ---\n",
      "--- 0.022423267364501953 seconds ---\n",
      "--- 2.869309663772583 seconds ---\n",
      "\n",
      " at iteration 28 , #values:  32  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 131:===================>                                     (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.5238454341888428 seconds ---\n",
      "--- 0.009307384490966797 seconds ---\n",
      "--- 2.855938673019409 seconds ---\n",
      "\n",
      " at iteration 29 , #values:  33  \n",
      "\n",
      "--- 2.463203191757202 seconds ---\n",
      "--- 0.014850378036499023 seconds ---\n",
      "--- 2.9914133548736572 seconds ---\n",
      "\n",
      " at iteration 30 , #values:  34  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 139:======================================>                  (2 + 1) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.502478837966919 seconds ---\n",
      "--- 0.008217811584472656 seconds ---\n",
      "--- 3.0175085067749023 seconds ---\n",
      "\n",
      " at iteration 31 , #values:  35  \n",
      "\n",
      "CPU times: user 3.48 s, sys: 852 ms, total: 4.33 s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# OPTIMIZED LOOP\n",
    "\n",
    "i = 0\n",
    "last_centers = 1\n",
    "start_time = time.time()\n",
    "\n",
    "while i < n_iter:# or len(bCent.value) < k:\n",
    "\n",
    "    '''\n",
    "    Nel ciclo for:\n",
    "        - Evaluate for each row l * d()^2 / phi\n",
    "        - Sample with that probability\n",
    "        - Broadcast centers to nodes\n",
    "        - Evaluate new cost\n",
    "        \n",
    "    Ricordiamoci che distance è già al quadrato e che phi è il logaritmo\n",
    "    '''\n",
    "    \n",
    "    # Evaluate the probability and select the new rows\n",
    "    new_rows = clean_X.rdd\\\n",
    "               .filter(lambda row: select_row(np.exp(np.log(row.__getitem__('minimum_cost'))-phi_iter)*l)).collect()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Update the broadcast\n",
    "    bCent = sc.broadcast(bCent.value + new_rows)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Update the minimum distance\n",
    "    if len(new_rows) == 1:\n",
    "        clean_X = clean_X.select('*').withColumn('minimum_cost', least('minimum_cost', sum((col(colname)-bCent.value[0][colname])**2 for colname in colnames) ))\n",
    "\n",
    "    elif len(new_rows) > 1:\n",
    "        clean_X = clean_X.select('*').withColumn('dummy', least(*[sum((col(colname)-bCent.value[center][colname])**2 for colname in colnames) for center in range(len(new_rows))] )).\\\n",
    "                  withColumn('minimum_cost', least('minimum_cost', 'dummy')).\\\n",
    "                  drop('dummy')\n",
    "\n",
    "    last_centers = len(bCent.value)\n",
    "\n",
    "    # Evaluate new cost\n",
    "    phi_iter = np.log(clean_X.agg({\"minimum_cost\": \"sum\"}).collect()[0][0])\n",
    "\n",
    "        \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "\n",
    "    i += 1\n",
    "    print(\"\\n at iteration\", i ,\", #values: \",len(bCent.value), \" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_X.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "\n",
    "# OPTIMIZED LOOP\n",
    "\n",
    "from pyspark.sql.functions import array\n",
    "\n",
    "i = 0\n",
    "last_centers = 1\n",
    "start_time = time.time()\n",
    "\n",
    "while i < n_iter:# or len(bCent.value) < k:\n",
    "\n",
    "    '''\n",
    "    Nel ciclo for:\n",
    "        - Evaluate for each row l * d()^2 / phi\n",
    "        - Sample with that probability\n",
    "        - Broadcast centers to nodes\n",
    "        - Evaluate new cost\n",
    "        \n",
    "    Ricordiamoci che distance è già al quadrato e che phi è il logaritmo\n",
    "    '''\n",
    "    \n",
    "    # Evaluate the probability and select the new rows\n",
    "    new_rows = clean_X.rdd\\\n",
    "               .filter(lambda row: select_row( l*row.__getitem__('minimum_cost')/np.exp(phi_iter) )).collect()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Update the broadcast\n",
    "    bCent = sc.broadcast(bCent.value + new_rows)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    # Update the minimum distance\n",
    "    if len(new_rows) > 0:\n",
    "        print(\"claisjnflkjasdnf\")\n",
    "        \n",
    "        \n",
    "        #create new column w/ minimum distance from new batch of centers\n",
    "            #clean_X.withColumn(\"new_distance\")\n",
    "        \n",
    "            #wx = clean_X.rdd.map(lambda row: (find_closest_center(row,bCent),1)).reduceByKey(lambda x,y: x+y).\\\n",
    "            #takeOrdered(over_sampled_centers) #o lambda x,y: x+y\n",
    "            #initial_cost = clean_X.select(['minimum_cost']).rdd.map(lambda x : x).reduce(sum)\n",
    "\n",
    "            #data_vals = clean_X.rdd.\\\n",
    "            #groupBy(lambda gk: 1).\\\n",
    "            #flatMapValues(lambda r: chooseNewDistance(r, last_centers)).\\\n",
    "            #values()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if i == 0:\n",
    "         #   data_vals_test = data_vals\n",
    "         #   print(data_vals.collect()[0][0])\n",
    "        \n",
    "        #data_schema = clean_X.schema\n",
    "        \n",
    "        print('\\n i =',i,'before: clean_X.count() = ',clean_X.count())\n",
    "        \n",
    "        #clean_X = spark.createDataFrame(data_vals, data_schema)\n",
    "\n",
    "        print('\\n i =',i,'after: clean_X.count() = ',clean_X.count())\n",
    "\n",
    "        # Evaluate new cost\n",
    "        phi_iter = np.log(clean_X.agg({\"minimum_cost\": \"sum\"}).collect()[0][0])\n",
    "\n",
    "        \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    last_centers = len(bCent.value)\n",
    "\n",
    "    i += 1\n",
    "    print(\"\\n at iteration\", i ,\", #values: \",len(bCent.value), \" \\n\")  \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vals_test = clean_X.rdd.\\\n",
    "            groupBy(lambda gk: 1).\\\n",
    "            flatMapValues(lambda r: chooseNewDistance(r, last_centers)).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vals_test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCent.value[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phi_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(bCent.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Select a subset of the possible centroids using k-means ++\n",
    "\n",
    "Using kmeans ++:\n",
    "\n",
    "Algorithm 1 k-means++(k) initialization.\n",
    "1: C ← sample a point uniformly at random from X\n",
    "2: while |C| < k do\n",
    "2\n",
    "3:\n",
    "Sample x ∈ X with probability dφX(x,C)\n",
    "(C)\n",
    "4:\n",
    "C ← C ∪ {"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCent_list = bCent.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCent = spark.createDataFrame(bCent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampled_centers = dfCent.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCent.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCent.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCent = sc.broadcast(bCent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bCent.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce size of dfCent to have only `k` centroids \n",
    "\n",
    "#### Step 1: calc weights $w_x$\n",
    "set wx to be the number of points in X closer to x than any other point in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx = clean_X.rdd.map(lambda row: (find_closest_center(row,bCent),1)).reduceByKey(lambda x,y: x+y).takeOrdered(over_sampled_centers) #o lambda x,y: x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx = (np.array(wx)[:,1]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx /= np.sum(wx)\n",
    "wx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Use weighted `k-means++`\n",
    "    2.1 Draw 1 random center\n",
    "    2.2 update cost function\n",
    "    2.3 repeat 1-2 until happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_center = np.random.choice(a=range(wx.shape[0]), size=1, p=wx) \n",
    "#first point sampled uniformly wrt distance\n",
    "first_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCent_ultimate = sc.broadcast(getrows(dfCent,first_center).collect())\n",
    "bCent_ultimate.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi0 = phi(dfCent, bCent_ultimate)\n",
    "phi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bCent_ultimate.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "i = 0\n",
    "while i < k: #n_iter or len(bCent.value) < k:\n",
    "    '''\n",
    "    Nel ciclo for:\n",
    "        - Evaluate for each row l * d()^2 / phi\n",
    "        - Sample with that probability\n",
    "        - Broadcast centers to nodes\n",
    "        - Evaluate new cost\n",
    "        \n",
    "    Ricordiamoci che distance è già al quadrato e che phi è il logaritmo\n",
    "    '''\n",
    "    \n",
    "    # Evaluate the probability and select the new rows\n",
    "    #probabilities = clean_X.rdd.map(lambda row: np.exp(np.log(distance(row,bCent))-phi_iter)*l)\n",
    "    rows_prob = np.array(dfCent.rdd\\\n",
    "    .map(lambda row: (np.exp(np.log(distance(row,bCent_ultimate))-phi0))).collect())\n",
    "    \n",
    "    #sample new random center\n",
    "    if i == 0:\n",
    "        print('rows_prob@wx \\n',rows_prob@wx, '\\n')\n",
    "    \n",
    "    another_index = np.random.choice(a=range(wx.shape[0]), size=1, p = rows_prob*wx/(rows_prob@wx) ) \n",
    "    \n",
    "    print(i ,'step: another_index = ', another_index,'\\n')\n",
    "    \n",
    "    another_center = getrows(dfCent, another_index).collect()\n",
    "    \n",
    "    # Update the broadcast\n",
    "    bCent_ultimate = sc.broadcast(bCent_ultimate.value + another_center)\n",
    "    \n",
    "    # Evaluate new cost\n",
    "    phi0 = phi(dfCent, bCent_ultimate)\n",
    "    \n",
    "    i += 1\n",
    "    print(\"\\n i: \",i,\"; bC.val =\",bCent_ultimate.value, \" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rows_prob*wx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Prendere la lista dei centroidi e farla diventare un distributed dataset\n",
    "- Fare una NUOVA lista di centroidi \n",
    "- for i in range(k):\n",
    "    pesca un singolo dato con probabilità d(x)/phi --> come fare?\n",
    "    aggiungilo alla lista\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "    - Capire come scegliere l\n",
    "    - Fare la normalizzazione dei dati (se la facciamo)\n",
    "    - Capire se abbiamo ottimizzato nel modo giusto\n",
    "    - Implementare tutto k means (optional)\n",
    "    - Creare un file gemello con un dataframe visualizzabile e vedere se ha senso\n",
    "    - Iniziare a fare i benchmark su cloud veneto\n",
    "    - Grafici etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop worker and master\n",
    "Stop the running Spark context (sc) and Spark session (spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use `docker compose down` to stop and clear all running containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scantinato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimized loop functions, 30.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        #print('OOOOO', len(new_rows))\n",
    "        #clean_X = clean_X.withColumn('dummy', \n",
    "         #         array(sum((col(colname)-bCent.value[center][colname])**2 for colname in colnames) for center in range(len(new_rows))))\n",
    "\n",
    "        #print('OOOOO', len(new_rows))\n",
    "        #clean_X = clean_X.withColumn('dummy', least(*[col(\"dummy\")[i] for i in range(len(new_rows))]))\n",
    "        \n",
    "#       # clean_X = clean_X.withColumn('dummy',\n",
    "#        #           least(*[(sum((col(colname)-bCent.value[center][colname])**2 for colname in colnames) for center in range(len(new_rows)))[i]\n",
    "#         #          for i in range(len(new_rows))]))\n",
    "\n",
    "#          #         least(*(sum((col(colname)-bCent.value[center][colname])**2 for colname in colnames) for center in range(len(new_rows)))))\n",
    "\n",
    "#         #df_with_min = df.withColumn(\"min_value\", least(*[col(\"values\")[i] for i in range(len(data[0][1]))]))\n",
    "\n",
    "        #print('OOOOO', len(new_rows))\n",
    "        #clean_X = clean_X.withColumn('minimum_cost', least(col('minimum_cost'), col('dummy')))\n",
    "\n",
    "        #print('OOOOO', len(new_rows))\n",
    "        #clean_X = clean_X.drop('dummy')\n",
    "\n",
    "        #last_centers = len(bCent.value)\n",
    "\n",
    "#         names = ['minimum_cost']\n",
    "        \n",
    "#         for center in range(len(new_rows)):\n",
    "#             name = 'dummy_'+str(center)\n",
    "#             clean_X = clean_X.withColumn( name, sum((col(colname)-bCent.value[center][colname])**2 for colname in colnames) )\n",
    "#             names.append(name)\n",
    "            \n",
    "#         column_list = (col(n) for n in names)\n",
    "#         clean_X = clean_X.withColumn('minimum_cost', least(*column_list))\n",
    "\n",
    "#         for center in range(len(new_rows)):\n",
    "#             name = 'dummy_'+str(center)\n",
    "#             clean_X = clean_X.drop( name )\n",
    "\n",
    "#         last_centers = len(bCent.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
